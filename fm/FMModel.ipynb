{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field sizes: [25, 445852, 36, 371, 4, 11328, 33995, 12, 7, 5, 4, 20, 2, 38, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8]\n",
      "INPUT_DIM: 491713\n"
     ]
    }
   ],
   "source": [
    "# 读取featureIndex数据，统计基本的信息，field等\n",
    "FIELD_SIZES = [0] * 26\n",
    "with open('../data/featindex.txt') as fin:\n",
    "    for line in fin:\n",
    "        line = line.strip().split(':')\n",
    "        if len(line) > 1:\n",
    "            featIndex = int(line[0]) - 1\n",
    "            FIELD_SIZES[featIndex] += 1\n",
    "   \n",
    "FIELD_OFFSETS = [sum(FIELD_SIZES[:i]) for i in range(len(FIELD_SIZES))]\n",
    "INPUT_DIM = sum(FIELD_SIZES)\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "print('field sizes:', FIELD_SIZES)\n",
    "print('INPUT_DIM:', INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取libsvm格式数据成稀疏矩阵形式\n",
    "# 0 5:1 9:1 140858:1 445908:1 446177:1 446293:1 449140:1 490778:1 491626:1 491634:1 491641:1 491645:1 491648:1 491668:1 491700:1 491708:1\n",
    "def read_data(file_name):\n",
    "    X = []\n",
    "    D = []\n",
    "    y = []\n",
    "    with open(file_name) as fin:\n",
    "        for line in fin:\n",
    "            fields = line.strip().split()\n",
    "            y_i = int(fields[0])\n",
    "            X_i = [int(x.split(':')[0]) for x in fields[1:]]\n",
    "            D_i = [int(x.split(':')[1]) for x in fields[1:]]\n",
    "            y.append(y_i)\n",
    "            X.append(X_i)\n",
    "            D.append(D_i)\n",
    "    y = np.reshape(np.array(y), [-1])\n",
    "    X = libsvm_2_coo(zip(X, D), (len(X), INPUT_DIM)).tocsr()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 工具函数，libsvm格式转成coo稀疏存储格式\n",
    "def libsvm_2_coo(libsvm_data, shape):\n",
    "    coo_rows = []\n",
    "    coo_cols = []\n",
    "    coo_data = []\n",
    "    n = 0\n",
    "    for x, d in libsvm_data:\n",
    "        coo_rows.extend([n] * len(x))\n",
    "        coo_cols.extend(x)\n",
    "        coo_data.extend(d)\n",
    "        n += 1\n",
    "    coo_rows = np.array(coo_rows)\n",
    "    coo_cols = np.array(coo_cols)\n",
    "    coo_data = np.array(coo_data)\n",
    "    return coo_matrix((coo_data, (coo_rows, coo_cols)), shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csr转成输入格式\n",
    "def csr_2_input(csr_mat):\n",
    "    if not isinstance(csr_mat, list):\n",
    "        coo_mat = csr_mat.tocoo()\n",
    "        indices = np.vstack((coo_mat.row, coo_mat.col)).transpose()\n",
    "        values = csr_mat.data\n",
    "        shape = csr_mat.shape\n",
    "        return indices, values, shape\n",
    "    else:\n",
    "        inputs = []\n",
    "        for csr_i in csr_mat:\n",
    "            inputs.append(csr_2_input(csr_i))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read finish\n",
      "train data size: (1742104, 491713)\n",
      "test data size: (300928, 491713)\n"
     ]
    }
   ],
   "source": [
    "train_file = '../data/train.txt'\n",
    "test_file = '../data/test.txt'\n",
    "input_dim = INPUT_DIM\n",
    "train_data = read_data(train_file)\n",
    "# train_data = shuffle(train_data)\n",
    "test_data = read_data(test_file)\n",
    "print('read finish')\n",
    "print('train data size:', train_data[0].shape)\n",
    "print('test data size:', test_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read finish\n",
      "train data size: (1742104, 491713)\n",
      "test data size: (300928, 491713)\n"
     ]
    }
   ],
   "source": [
    "train_data = pkl.load(open('../data/train.pkl', 'rb'))\n",
    "#train_data = shuffle(train_data)\n",
    "test_data = pkl.load(open('../data/test.pkl', 'rb'))\n",
    "# pkl.dump(train_data, open('../data/train.pkl', 'wb'))\n",
    "# pkl.dump(test_data, open('../data/test.pkl', 'wb'))\n",
    "print('read finish')\n",
    "print('train data size:', train_data[0].shape)\n",
    "print('test data size:', test_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练集与测试集\n",
    "train_size = train_data[0].shape[0]\n",
    "test_size = test_data[0].shape[0]\n",
    "num_feas = len(FIELD_SIZES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在tensorflow中初始化各种参数变量\n",
    "# init_vars = [var_name, var_shape, init_method, dtype]\n",
    "STDDEV = 1e-3\n",
    "MINVAL = -1e-3\n",
    "MAXVAL = 1e-3\n",
    "def init_var_map(init_vars, init_path=None):\n",
    "    if init_path is not None:\n",
    "        load_var_map = pkl.load(open(init_path, 'rb'))\n",
    "        print('load variable map from', init_path, load_var_map.keys())\n",
    "    var_map = {}\n",
    "    for var_name, var_shape, init_method, dtype in init_vars:\n",
    "        if init_method == 'zero':\n",
    "            var_map[var_name] = tf.Variable(tf.zeros(var_shape, dtype=dtype), name=var_name, dtype=dtype)\n",
    "        elif init_method == 'one':\n",
    "            var_map[var_name] = tf.Variable(tf.ones(var_shape, dtype=dtype), name=var_name, dtype=dtype)\n",
    "        elif init_method == 'normal':\n",
    "            var_map[var_name] = tf.Variable(tf.random_normal(var_shape, mean=0.0, stddev=STDDEV, dtype=dtype),\n",
    "                                            name=var_name, dtype=dtype)\n",
    "        elif init_method == 'tnormal':\n",
    "            var_map[var_name] = tf.Variable(tf.truncated_normal(var_shape, mean=0.0, stddev=STDDEV, dtype=dtype),\n",
    "                                            name=var_name, dtype=dtype)\n",
    "        elif init_method == 'uniform':\n",
    "            var_map[var_name] = tf.Variable(tf.random_uniform(var_shape, minval=MINVAL, maxval=MAXVAL, dtype=dtype),\n",
    "                                            name=var_name, dtype=dtype)\n",
    "        elif init_method == 'xavier':\n",
    "            maxval = np.sqrt(6. / np.sum(var_shape))\n",
    "            minval = -maxval\n",
    "            var_map[var_name] = tf.Variable(tf.random_uniform(var_shape, minval=minval, maxval=maxval, dtype=dtype),\n",
    "                                            name=var_name, dtype=dtype)\n",
    "        elif isinstance(init_method, int) or isinstance(init_method, float):\n",
    "            var_map[var_name] = tf.Variable(tf.ones(var_shape, dtype=dtype) * init_method, name=var_name, dtype=dtype)\n",
    "        elif init_method in load_var_map:\n",
    "            if load_var_map[init_method].shape == tuple(var_shape):\n",
    "                var_map[var_name] = tf.Variable(load_var_map[init_method], name=var_name, dtype=dtype)\n",
    "            else:\n",
    "                print('BadParam: init method', init_method, 'shape', var_shape, load_var_map[init_method].shape)\n",
    "        else:\n",
    "            print('BadParam: init method', init_method)\n",
    "    return var_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 不同的优化器选择\n",
    "def get_optimizer(opt_algo, learning_rate, loss):\n",
    "    if opt_algo == 'adaldeta':\n",
    "        return tf.train.AdadeltaOptimizer(learning_rate).minimize(loss)\n",
    "    elif opt_algo == 'adagrad':\n",
    "        return tf.train.AdagradOptimizer(learning_rate).minimize(loss)\n",
    "    elif opt_algo == 'adam':\n",
    "        return tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    elif opt_algo == 'ftrl':\n",
    "        return tf.train.FtrlOptimizer(learning_rate).minimize(loss)\n",
    "    elif opt_algo == 'gd':\n",
    "        return tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    elif opt_algo == 'padagrad':\n",
    "        return tf.train.ProximalAdagradOptimizer(learning_rate).minimize(loss)\n",
    "    elif opt_algo == 'pgd':\n",
    "        return tf.train.ProximalGradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    elif opt_algo == 'rmsprop':\n",
    "        return tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "    else:\n",
    "        return tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据切片\n",
    "def slice(csr_data, start=0, size=-1):\n",
    "    if not isinstance(csr_data[0], list):\n",
    "        if size == -1 or start + size >= csr_data[0].shape[0]:\n",
    "            slc_data = csr_data[0][start:]\n",
    "            slc_labels = csr_data[1][start:]\n",
    "        else:\n",
    "            slc_data = csr_data[0][start:start + size]\n",
    "            slc_labels = csr_data[1][start:start + size]\n",
    "    else:\n",
    "        if size == -1 or start + size >= csr_data[0][0].shape[0]:\n",
    "            slc_data = []\n",
    "            for d_i in csr_data[0]:\n",
    "                slc_data.append(d_i[start:])\n",
    "            slc_labels = csr_data[1][start:]\n",
    "        else:\n",
    "            slc_data = []\n",
    "            for d_i in csr_data[0]:\n",
    "                slc_data.append(d_i[start:start + size])\n",
    "            slc_labels = csr_data[1][start:start + size]\n",
    "    return csr_2_input(slc_data), slc_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义基类模型\n",
    "dtype = tf.float32\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.sess = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.layer_keeps = None\n",
    "        self.vars = None\n",
    "        self.keep_prob_train = None\n",
    "        self.keep_prob_test = None\n",
    "\n",
    "    # run model\n",
    "    def run(self, fetches, X=None, y=None, mode='train'):\n",
    "            # 通过feed_dict传入数据\n",
    "            feed_dict = {}\n",
    "            if type(self.X) is list:\n",
    "                for i in range(len(X)):\n",
    "                    feed_dict[self.X[i]] = X[i]\n",
    "            else:\n",
    "                feed_dict[self.X] = X\n",
    "            if y is not None:\n",
    "                feed_dict[self.y] = y\n",
    "            if self.layer_keeps is not None:\n",
    "                if mode == 'train':\n",
    "                    feed_dict[self.layer_keeps] = self.keep_prob_train\n",
    "                elif mode == 'test':\n",
    "                    feed_dict[self.layer_keeps] = self.keep_prob_test\n",
    "            #通过session.run去执行op\n",
    "            return self.sess.run(fetches, feed_dict)\n",
    "\n",
    "    # 模型参数持久化\n",
    "    def dump(self, model_path):\n",
    "        var_map = {}\n",
    "        for name, var in self.vars.iteritems():\n",
    "            var_map[name] = self.run(var)\n",
    "        pkl.dump(var_map, open(model_path, 'wb'))\n",
    "        print('model dumped at', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FM Model\n",
    "$\\sum_{i=1}^{n-1}\\sum_{j=i+1}^n<v_i,v_j>x_ix_j = \\frac{1}{2}\\sum_{j=1}^k[\\sum_{i=1}^n(v_{i,j}x_i)^2 - \\sum_{i=1}^n(v_{i,i}^2x_i^2)]$\n",
    "\n",
    "变量：\n",
    "- xv: $\\sum_{j=1}^k[\\sum_{i=1}^n(v_{i,j}x_i)^2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FMModel(Model):\n",
    "    def __init__(self, input_dim=None, output_dim=1, factor_order=10, init_path=None, opt_algo='gd', learning_rate=1e-2,\n",
    "                 l2_w=0, l2_v=0, random_seed=None):\n",
    "        Model.__init__(self)\n",
    "        # 一次w、二次交叉v、偏置项b\n",
    "        init_vars = [('w', [input_dim, output_dim], 'xavier', dtype),\n",
    "                     ('v', [input_dim, factor_order], 'xavier', dtype),\n",
    "                     ('b', [output_dim], 'zero', dtype)]        \n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            if random_seed is not None:\n",
    "                tf.set_random_seed(random_seed)\n",
    "            self.X = tf.sparse_placeholder(dtype)\n",
    "            self.y = tf.placeholder(dtype)\n",
    "            self.vars = init_var_map(init_vars, init_path)\n",
    "\n",
    "            w = self.vars['w']\n",
    "            v = self.vars['v']\n",
    "            b = self.vars['b']\n",
    "            # 一次项\n",
    "            xw = tf.sparse_tensor_dense_matmul(self.X, w)\n",
    "            \n",
    "            # 二次项： 交叉项 - 平方项\n",
    "            X_square = tf.SparseTensor(self.X.indices, tf.square(self.X.values), tf.to_int64(tf.shape(self.X)))\n",
    "            xv2 = tf.square(tf.sparse_tensor_dense_matmul(self.X, v))\n",
    "            x2v2 = tf.sparse_tensor_dense_matmul(X_square, tf.square(v))\n",
    "            p = 0.5 * tf.reshape(tf.reduce_sum(xv2 - x2v2, 1), [-1, output_dim])\n",
    "            \n",
    "            logits = tf.reshape(xw + b + p, [-1])\n",
    "            self.y_prob = tf.sigmoid(logits)\n",
    "            \n",
    "            # 损失函数\n",
    "            self.loss = tf.reduce_mean(\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=self.y)) + \\\n",
    "                        l2_w * tf.nn.l2_loss(xw) + \\\n",
    "                        l2_v * tf.nn.l2_loss(xv2)\n",
    "            self.optimizer = get_optimizer(opt_algo, learning_rate, self.loss)\n",
    "            \n",
    "            config = tf.ConfigProto()\n",
    "            self.sess = tf.Session(config=config)\n",
    "            tf.global_variables_initializer().run(session=self.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_dim': 491713, 'factor_order': 10, 'opt_algo': 'gd', 'learning_rate': 0.1, 'l2_w': 0, 'l2_v': 0}\n"
     ]
    }
   ],
   "source": [
    "# 超参数设定\n",
    "min_round = 1\n",
    "num_round = 20\n",
    "early_stop_round = 5\n",
    "batch_size = 1024\n",
    "\n",
    "field_sizes = FIELD_SIZES\n",
    "field_offsets = FIELD_OFFSETS\n",
    "\n",
    "# FM参数设定\n",
    "fm_params = {\n",
    "    'input_dim': input_dim,\n",
    "    'factor_order': 10,\n",
    "    'opt_algo': 'gd',\n",
    "    'learning_rate': 0.1,\n",
    "    'l2_w': 0,\n",
    "    'l2_v': 0,\n",
    "}\n",
    "print(fm_params)\n",
    "fm_model = FMModel(**fm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training FM...\n",
      "[0]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tloss (with l2 norm):0.013319\ttrain-auc: 0.611436\teval-auc: 0.626339\n",
      "[1]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tloss (with l2 norm):0.006374\ttrain-auc: 0.625287\teval-auc: 0.648224\n",
      "[2]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  9% |######                                                                  |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\tloss (with l2 norm):0.006258\ttrain-auc: 0.637162\teval-auc: 0.661508\n",
      "[3]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\tloss (with l2 norm):0.006218\ttrain-auc: 0.647016\teval-auc: 0.672154\n",
      "[4]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  8% |#####                                                                   |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\tloss (with l2 norm):0.006194\ttrain-auc: 0.654740\teval-auc: 0.680905\n",
      "[5]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  8% |#####                                                                   |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tloss (with l2 norm):0.006176\ttrain-auc: 0.660925\teval-auc: 0.687084\n",
      "[6]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\tloss (with l2 norm):0.006161\ttrain-auc: 0.665848\teval-auc: 0.692500\n",
      "[7]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 11% |########                                                                |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\tloss (with l2 norm):0.006149\ttrain-auc: 0.669692\teval-auc: 0.696592\n",
      "[8]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 11% |########                                                                |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\tloss (with l2 norm):0.006138\ttrain-auc: 0.672975\teval-auc: 0.699832\n",
      "[9]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\tloss (with l2 norm):0.006128\ttrain-auc: 0.675740\teval-auc: 0.702804\n",
      "[10]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tloss (with l2 norm):0.006119\ttrain-auc: 0.678206\teval-auc: 0.705429\n",
      "[11]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\tloss (with l2 norm):0.006111\ttrain-auc: 0.680468\teval-auc: 0.707831\n",
      "[12]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\tloss (with l2 norm):0.006103\ttrain-auc: 0.682616\teval-auc: 0.710113\n",
      "[13]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\tloss (with l2 norm):0.006096\ttrain-auc: 0.684681\teval-auc: 0.712213\n",
      "[14]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\tloss (with l2 norm):0.006090\ttrain-auc: 0.686688\teval-auc: 0.714255\n",
      "[15]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  5% |####                                                                    |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\tloss (with l2 norm):0.006083\ttrain-auc: 0.688651\teval-auc: 0.716265\n",
      "[16]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\tloss (with l2 norm):0.006077\ttrain-auc: 0.690582\teval-auc: 0.718276\n",
      "[17]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\tloss (with l2 norm):0.006071\ttrain-auc: 0.692485\teval-auc: 0.720228\n",
      "[18]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\tloss (with l2 norm):0.006065\ttrain-auc: 0.694355\teval-auc: 0.722149\n",
      "[19]\ttraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  8% |#####                                                                   |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\tevaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\tloss (with l2 norm):0.006060\ttrain-auc: 0.696178\teval-auc: 0.724021\n"
     ]
    }
   ],
   "source": [
    "def train(model):\n",
    "    print(\"training FM...\")\n",
    "    history_score = []\n",
    "    for i in range(num_round):\n",
    "        # 同样是优化器和损失两个op\n",
    "        fetches = [model.optimizer, model.loss]\n",
    "        if batch_size > 0:\n",
    "            ls = []\n",
    "            bar = progressbar.ProgressBar()\n",
    "            print('[%d]\\ttraining...' % i)\n",
    "            for j in bar(range(int(train_size / batch_size + 1))):\n",
    "                X_i, y_i = slice(train_data, j * batch_size, batch_size)\n",
    "                # 训练\n",
    "                _, l = model.run(fetches, X_i, y_i)\n",
    "                ls.append(l)\n",
    "        elif batch_size == -1:\n",
    "            X_i, y_i = slice(train_data)\n",
    "            _, l = model.run(fetches, X_i, y_i)\n",
    "            ls = [l]\n",
    "        train_preds = []\n",
    "        print('[%d]\\tevaluating...' % i)\n",
    "        bar = progressbar.ProgressBar()\n",
    "        for j in bar(range(int(train_size / 10000 + 1))):\n",
    "            X_i, _ = slice(train_data, j * 10000, 10000)\n",
    "            preds = model.run(model.y_prob, X_i, mode='test')\n",
    "            train_preds.extend(preds)\n",
    "        test_preds = []\n",
    "        bar = progressbar.ProgressBar()\n",
    "        for j in bar(range(int(test_size / 10000 + 1))):\n",
    "            X_i, _ = slice(test_data, j * 10000, 10000)\n",
    "            preds = model.run(model.y_prob, X_i, mode='test')\n",
    "            test_preds.extend(preds)\n",
    "        train_score = roc_auc_score(train_data[1], train_preds)\n",
    "        test_score = roc_auc_score(test_data[1], test_preds)\n",
    "        print('[%d]\\tloss (with l2 norm):%f\\ttrain-auc: %f\\teval-auc: %f' % (i, np.mean(ls), train_score, test_score))\n",
    "        history_score.append(test_score)\n",
    "        if i > min_round and i > early_stop_round:\n",
    "            if np.argmax(history_score) == i - early_stop_round and history_score[-1] - history_score[\n",
    "                        -1 * early_stop_round] < 1e-5:\n",
    "                print('early stop\\nbest iteration:\\n[%d]\\teval-auc: %f' % (\n",
    "                    np.argmax(history_score), np.max(history_score)))\n",
    "                break\n",
    "\n",
    "train(fm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
